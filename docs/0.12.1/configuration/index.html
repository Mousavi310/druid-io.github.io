<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Apache Druid">
<meta name="keywords" content="druid,kafka,database,analytics,streaming,real-time,real time,apache,open source">
<meta name="author" content="Apache Software Foundation">

<title>Druid | </title>

<link rel="alternate" type="application/atom+xml" href="/feed">
<link rel="shortcut icon" href="/img/favicon.png">

<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">

<link href='//fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700,300italic|Open+Sans:300italic,400italic,600italic,400,300,600,700' rel='stylesheet' type='text/css'>

<link rel="stylesheet" href="/css/bootstrap-pure.css?v=1.0">
<link rel="stylesheet" href="/css/main.css?v=1.0">
<link rel="stylesheet" href="/css/header.css?v=1.0">
<link rel="stylesheet" href="/css/footer.css?v=1.0">
<link rel="stylesheet" href="/css/syntax.css?v=1.0">
<link rel="stylesheet" href="/css/docs.css?v=1.0">

<script>
  (function() {
    var cx = '000162378814775985090:molvbm0vggm';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
        '//cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>


  </head>

  <body>
    <!-- Start page_header include -->
<script src="//ajax.googleapis.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>

<div class="top-navigator">
  <div class="container">
    <div class="left-cont">
      <a class="logo" href="/"><span class="druid-logo"></span></a>
    </div>
    <div class="right-cont">
      <ul class="links">
        <li class=""><a href="/technology">Technology</a></li>
        <li class=""><a href="/use-cases">Use Cases</a></li>
        <li class=""><a href="/druid-powered">Powered By</a></li>
        <li class=""><a href="/docs/latest/design/">Docs</a></li>
        <li class=""><a href="https://druid.apache.org/community/">Community</a></li>
        <li class=" button-link"><a href="/downloads.html">Download</a></li>
      </ul>
    </div>
  </div>
  <div class="action-button menu-icon">
    <span class="fa fa-bars"></span> MENU
  </div>
  <div class="action-button menu-icon-close">
    <span class="fa fa-times"></span> MENU
  </div>
</div>

<script type="text/javascript">
  var $menu = $('.right-cont');
  var $menuIcon = $('.menu-icon');
  var $menuIconClose = $('.menu-icon-close');

  function showMenu() {
    $menu.fadeIn(100);
    $menuIcon.fadeOut(100);
    $menuIconClose.fadeIn(100);
  }

  $menuIcon.click(showMenu);

  function hideMenu() {
    $menu.fadeOut(100);
    $menuIconClose.fadeOut(100);
    $menuIcon.fadeIn(100);
  }

  $menuIconClose.click(hideMenu);

  $(window).resize(function() {
    if ($(window).width() >= 840) {
      $menu.fadeIn(100);
      $menuIcon.fadeOut(100);
      $menuIconClose.fadeOut(100);
    }
    else {
      $menu.fadeOut(100);
      $menuIcon.fadeIn(100);
      $menuIconClose.fadeOut(100);
    }
  });
</script>

<!-- Stop page_header include -->


    <div class="container doc-container">
      
      

      
      <p> Looking for the <a href="/docs/0.14.0-incubating/">latest stable documentation</a>?</p>
      

      <div class="row">
        <div class="col-md-9 doc-content">
          <p>
            <a class="btn btn-default btn-xs visible-xs-inline-block visible-sm-inline-block" href="#toc">Table of Contents</a>
          </p>
          <h1 id="configuring-druid">Configuring Druid</h1>

<p>This describes the common configuration shared by all Druid nodes. These configurations can be defined in the <code>common.runtime.properties</code> file.</p>

<h2 id="jvm-configuration-best-practices">JVM Configuration Best Practices</h2>

<p>There are four JVM parameters that we set on all of our processes:</p>

<ol>
<li> <code>-Duser.timezone=UTC</code> This sets the default timezone of the JVM to UTC. We always set this and do not test with other default timezones, so local timezones might work, but they also might uncover weird and interesting bugs. To issue queries in a non-UTC timezone, see <a href="../querying/granularities.html#period-granularities">query granularities</a></li>
<li> <code>-Dfile.encoding=UTF-8</code> This is similar to timezone, we test assuming UTF-8. Local encodings might work, but they also might result in weird and interesting bugs.</li>
<li> <code>-Djava.io.tmpdir=&lt;a path&gt;</code> Various parts of the system that interact with the file system do it via temporary files, and these files can get somewhat large. Many production systems are set up to have small (but fast) <code>/tmp</code> directories, which can be problematic with Druid so we recommend pointing the JVMâ€™s tmp directory to something with a little more meat.</li>
<li> <code>-Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager</code> This allows log4j2 to handle logs for non-log4j2 components (like jetty) which use standard java logging.</li>
</ol>

<h3 id="extensions">Extensions</h3>

<p>Many of Druid&#39;s external dependencies can be plugged in as modules. Extensions can be provided using the following configs:</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.extensions.directory</code></td>
<td>The root extension directory where user can put extensions related files. Druid will load extensions stored under this directory.</td>
<td><code>extensions</code> (This is a relative path to Druid&#39;s working directory)</td>
</tr>
<tr>
<td><code>druid.extensions.hadoopDependenciesDir</code></td>
<td>The root hadoop dependencies directory where user can put hadoop related dependencies files. Druid will load the dependencies based on the hadoop coordinate specified in the hadoop index task.</td>
<td><code>hadoop-dependencies</code> (This is a relative path to Druid&#39;s working directory</td>
</tr>
<tr>
<td><code>druid.extensions.loadList</code></td>
<td>A JSON array of extensions to load from extension directories by Druid. If it is not specified, its value will be <code>null</code> and Druid will load all the extensions under <code>druid.extensions.directory</code>. If its value is empty list <code>[]</code>, then no extensions will be loaded at all. It is also allowed to specify absolute path of other custom extensions not stored in the common extensions directory.</td>
<td>null</td>
</tr>
<tr>
<td><code>druid.extensions.searchCurrentClassloader</code></td>
<td>This is a boolean flag that determines if Druid will search the main classloader for extensions.  It defaults to true but can be turned off if you have reason to not automatically add all modules on the classpath.</td>
<td>true</td>
</tr>
<tr>
<td><code>druid.extensions.hadoopContainerDruidClasspath</code></td>
<td>Hadoop Indexing launches hadoop jobs and this configuration provides way to explicitly set the user classpath for the hadoop job. By default this is computed automatically by druid based on the druid process classpath and set of extensions. However, sometimes you might want to be explicit to resolve dependency conflicts between druid and hadoop.</td>
<td>null</td>
</tr>
<tr>
<td><code>druid.extensions.addExtensionsToHadoopContainer</code></td>
<td>Only applicable if <code>druid.extensions.hadoopContainerDruidClasspath</code> is provided. If set to true, then extensions specified in the loadList are added to hadoop container classpath. Note that when <code>druid.extensions.hadoopContainerDruidClasspath</code> is not provided then extensions are always added to hadoop container classpath.</td>
<td>false</td>
</tr>
</tbody></table>

<h3 id="modules">Modules</h3>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.modules.excludeList</code></td>
<td>A JSON array of canonical class names (e. g. <code>&quot;io.druid.somepackage.SomeModule&quot;</code>) of module classes which shouldn&#39;t be loaded, even if they are found in extensions specified by <code>druid.extensions.loadList</code>, or in the list of core modules specified to be loaded on a particular Druid node type. Useful when some useful extension contains some module, which shouldn&#39;t be loaded on some Druid node type because some dependencies of that module couldn&#39;t be satisfied.</td>
<td>[]</td>
</tr>
</tbody></table>

<h3 id="zookeeper">Zookeeper</h3>

<p>We recommend just setting the base ZK path and the ZK service host, but all ZK paths that Druid uses can be overwritten to absolute paths.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.zk.paths.base</code></td>
<td>Base Zookeeper path.</td>
<td><code>/druid</code></td>
</tr>
<tr>
<td><code>druid.zk.service.host</code></td>
<td>The ZooKeeper hosts to connect to. This is a REQUIRED property and therefore a host address must be supplied.</td>
<td>none</td>
</tr>
</tbody></table>

<h4 id="zookeeper-behavior">Zookeeper Behavior</h4>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.zk.service.sessionTimeoutMs</code></td>
<td>ZooKeeper session timeout, in milliseconds.</td>
<td><code>30000</code></td>
</tr>
<tr>
<td><code>druid.zk.service.compress</code></td>
<td>Boolean flag for whether or not created Znodes should be compressed.</td>
<td><code>true</code></td>
</tr>
<tr>
<td><code>druid.zk.service.acl</code></td>
<td>Boolean flag for whether or not to enable ACL security for ZooKeeper. If ACL is enabled, zNode creators will have all permissions.</td>
<td><code>false</code></td>
</tr>
</tbody></table>

<h4 id="path-configuration">Path Configuration</h4>

<p>Druid interacts with ZK through a set of standard path configurations. We recommend just setting the base ZK path, but all ZK paths that Druid uses can be overwritten to absolute paths.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.zk.paths.base</code></td>
<td>Base Zookeeper path.</td>
<td><code>/druid</code></td>
</tr>
<tr>
<td><code>druid.zk.paths.propertiesPath</code></td>
<td>Zookeeper properties path.</td>
<td><code>${druid.zk.paths.base}/properties</code></td>
</tr>
<tr>
<td><code>druid.zk.paths.announcementsPath</code></td>
<td>Druid node announcement path.</td>
<td><code>${druid.zk.paths.base}/announcements</code></td>
</tr>
<tr>
<td><code>druid.zk.paths.liveSegmentsPath</code></td>
<td>Current path for where Druid nodes announce their segments.</td>
<td><code>${druid.zk.paths.base}/segments</code></td>
</tr>
<tr>
<td><code>druid.zk.paths.loadQueuePath</code></td>
<td>Entries here cause historical nodes to load and drop segments.</td>
<td><code>${druid.zk.paths.base}/loadQueue</code></td>
</tr>
<tr>
<td><code>druid.zk.paths.coordinatorPath</code></td>
<td>Used by the coordinator for leader election.</td>
<td><code>${druid.zk.paths.base}/coordinator</code></td>
</tr>
<tr>
<td><code>druid.zk.paths.servedSegmentsPath</code></td>
<td>@Deprecated. Legacy path for where Druid nodes announce their segments.</td>
<td><code>${druid.zk.paths.base}/servedSegments</code></td>
</tr>
</tbody></table>

<p>The indexing service also uses its own set of paths. These configs can be included in the common configuration.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.zk.paths.indexer.base</code></td>
<td>Base zookeeper path for</td>
<td><code>${druid.zk.paths.base}/indexer</code></td>
</tr>
<tr>
<td><code>druid.zk.paths.indexer.announcementsPath</code></td>
<td>Middle managers announce themselves here.</td>
<td><code>${druid.zk.paths.indexer.base}/announcements</code></td>
</tr>
<tr>
<td><code>druid.zk.paths.indexer.tasksPath</code></td>
<td>Used to assign tasks to middle managers.</td>
<td><code>${druid.zk.paths.indexer.base}/tasks</code></td>
</tr>
<tr>
<td><code>druid.zk.paths.indexer.statusPath</code></td>
<td>Parent path for announcement of task statuses.</td>
<td><code>${druid.zk.paths.indexer.base}/status</code></td>
</tr>
</tbody></table>

<p>If <code>druid.zk.paths.base</code> and <code>druid.zk.paths.indexer.base</code> are both set, and none of the other <code>druid.zk.paths.*</code> or <code>druid.zk.paths.indexer.*</code> values are set, then the other properties will be evaluated relative to their respective <code>base</code>.
For example, if <code>druid.zk.paths.base</code> is set to <code>/druid1</code> and <code>druid.zk.paths.indexer.base</code> is set to <code>/druid2</code> then <code>druid.zk.paths.announcementsPath</code> will default to <code>/druid1/announcements</code> while <code>druid.zk.paths.indexer.announcementsPath</code> will default to <code>/druid2/announcements</code>.</p>

<p>The following path is used for service discovery. It is <strong>not</strong> affected by <code>druid.zk.paths.base</code> and <strong>must</strong> be specified separately.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.discovery.curator.path</code></td>
<td>Services announce themselves under this ZooKeeper path.</td>
<td><code>/druid/discovery</code></td>
</tr>
</tbody></table>

<h3 id="exhibitor">Exhibitor</h3>

<p><a href="https://github.com/Netflix/exhibitor/wiki">Exhibitor</a> is a supervisor system for ZooKeeper.
Exhibitor can dynamically scale-up/down the cluster of ZooKeeper servers.
Druid can update self-owned list of ZooKeeper servers through Exhibitor without restarting.
That is, it allows Druid to keep the connections of Exhibitor-supervised ZooKeeper servers.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.exhibitor.service.hosts</code></td>
<td>A JSON array which contains the hostnames of Exhibitor instances. Please specify this property if you want to use Exhibitor-supervised cluster.</td>
<td>none</td>
</tr>
<tr>
<td><code>druid.exhibitor.service.port</code></td>
<td>The REST port used to connect to Exhibitor.</td>
<td><code>8080</code></td>
</tr>
<tr>
<td><code>druid.exhibitor.service.restUriPath</code></td>
<td>The path of the REST call used to get the server set.</td>
<td><code>/exhibitor/v1/cluster/list</code></td>
</tr>
<tr>
<td><code>druid.exhibitor.service.useSsl</code></td>
<td>Boolean flag for whether or not to use https protocol.</td>
<td><code>false</code></td>
</tr>
<tr>
<td><code>druid.exhibitor.service.pollingMs</code></td>
<td>How ofter to poll the exhibitors for the list</td>
<td><code>10000</code></td>
</tr>
</tbody></table>

<p>Note that <code>druid.zk.service.host</code> is used as a backup in case an Exhibitor instance can&#39;t be contacted and therefore should still be set.</p>

<h3 id="startup-logging">Startup Logging</h3>

<p>All nodes can log debugging information on startup.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.startup.logging.logProperties</code></td>
<td>Log all properties on startup (from common.runtime.properties, runtime.properties, and the JVM command line).</td>
<td>false</td>
</tr>
<tr>
<td><code>druid.startup.logging.maskProperties</code></td>
<td>Masks sensitive properties (passwords, for example) containing theses words.</td>
<td>[&quot;password&quot;]</td>
</tr>
</tbody></table>

<p>Note that some sensitive information may be logged if these settings are enabled.</p>

<h3 id="request-logging">Request Logging</h3>

<p>All nodes that can serve queries can also log the query requests they see.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.request.logging.type</code></td>
<td>Choices: noop, file, emitter, slf4j, filtered, composing. How to log every query request.</td>
<td>noop</td>
</tr>
</tbody></table>

<p>Note that, you can enable sending all the HTTP requests to log by setting  &quot;io.druid.jetty.RequestLog&quot; to DEBUG level. See <a href="../configuration/logging.html">Logging</a></p>

<h4 id="file-request-logging">File Request Logging</h4>

<p>Daily request logs are stored on disk.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.request.logging.dir</code></td>
<td>Historical, Realtime and Broker nodes maintain request logs of all of the requests they get (interacton is via POST, so normal request logs donâ€™t generally capture information about the actual query), this specifies the directory to store the request logs in</td>
<td>none</td>
</tr>
</tbody></table>

<h4 id="emitter-request-logging">Emitter Request Logging</h4>

<p>Every request is emitted to some external location.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.request.logging.feed</code></td>
<td>Feed name for requests.</td>
<td>none</td>
</tr>
</tbody></table>

<h4 id="slf4j-request-logging">SLF4J Request Logging</h4>

<p>Every request is logged via SLF4J. Queries are serialized into JSON in the log message regardless of the SJF4J format specification. They will be logged under the class <code>io.druid.server.log.LoggingRequestLogger</code>.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.request.logging.setMDC</code></td>
<td>If MDC entries should be set in the log entry. Your logging setup still has to be configured to handle MDC to format this data</td>
<td>false</td>
</tr>
<tr>
<td><code>druid.request.logging.setContextMDC</code></td>
<td>If the druid query <code>context</code> should be added to the MDC entries. Has no effect unless <code>setMDC</code> is <code>true</code></td>
<td>false</td>
</tr>
</tbody></table>

<p>MDC fields populated with <code>setMDC</code>:</p>

<table><thead>
<tr>
<th>MDC field</th>
<th>Description</th>
</tr>
</thead><tbody>
<tr>
<td><code>queryId</code></td>
<td>The query ID</td>
</tr>
<tr>
<td><code>dataSource</code></td>
<td>The datasource the query was against</td>
</tr>
<tr>
<td><code>queryType</code></td>
<td>The type of the query</td>
</tr>
<tr>
<td><code>hasFilters</code></td>
<td>If the query has any filters</td>
</tr>
<tr>
<td><code>remoteAddr</code></td>
<td>The remote address of the requesting client</td>
</tr>
<tr>
<td><code>duration</code></td>
<td>The duration of the query interval</td>
</tr>
<tr>
<td><code>resultOrdering</code></td>
<td>The ordering of results</td>
</tr>
<tr>
<td><code>descending</code></td>
<td>If the query is a descending query</td>
</tr>
</tbody></table>

<h4 id="filtered-request-logging">Filtered Request Logging</h4>

<p>Filtered Request Logger filters requests based on a configurable query/time threshold. Only request logs where query/time is above the threshold are emitted.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.request.logging.queryTimeThresholdMs</code></td>
<td>Threshold value for query/time in milliseconds.</td>
<td>0 i.e no filtering</td>
</tr>
<tr>
<td><code>druid.request.logging.delegate</code></td>
<td>Delegate request logger to log requests.</td>
<td>none</td>
</tr>
</tbody></table>

<h4 id="composite-request-logging">Composite Request Logging</h4>

<p>Composite Request Logger emits request logs to multiple request loggers.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.request.logging.loggerProviders</code></td>
<td>List of request loggers for emitting request logs.</td>
<td>none</td>
</tr>
</tbody></table>

<h3 id="enabling-metrics">Enabling Metrics</h3>

<p>Druid nodes periodically emit metrics and different metrics monitors can be included. Each node can overwrite the default list of monitors.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.monitoring.emissionPeriod</code></td>
<td>How often metrics are emitted.</td>
<td>PT1m</td>
</tr>
<tr>
<td><code>druid.monitoring.monitors</code></td>
<td>Sets list of Druid monitors used by a node. See below for names and more information. For example, you can specify monitors for a Broker with <code>druid.monitoring.monitors=[&quot;io.druid.java.util.metrics.SysMonitor&quot;,&quot;io.druid.java.util.metrics.JvmMonitor&quot;]</code>.</td>
<td>none (no monitors)</td>
</tr>
</tbody></table>

<p>The following monitors are available:</p>

<table><thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead><tbody>
<tr>
<td><code>io.druid.client.cache.CacheMonitor</code></td>
<td>Emits metrics (to logs) about the segment results cache for Historical and Broker nodes. Reports typical cache statistics include hits, misses, rates, and size (bytes and number of entries), as well as timeouts and and errors.</td>
</tr>
<tr>
<td><code>io.druid.java.util.metrics.SysMonitor</code></td>
<td>This uses the <a href="http://www.hyperic.com/products/sigar">SIGAR library</a> to report on various system activities and statuses.</td>
</tr>
<tr>
<td><code>io.druid.server.metrics.HistoricalMetricsMonitor</code></td>
<td>Reports statistics on Historical nodes.</td>
</tr>
<tr>
<td><code>io.druid.java.util.metrics.JvmMonitor</code></td>
<td>Reports various JVM-related statistics.</td>
</tr>
<tr>
<td><code>io.druid.java.util.metrics.JvmCpuMonitor</code></td>
<td>Reports statistics of CPU consumption by the JVM.</td>
</tr>
<tr>
<td><code>io.druid.java.util.metrics.CpuAcctDeltaMonitor</code></td>
<td>Reports consumed CPU as per the cpuacct cgroup.</td>
</tr>
<tr>
<td><code>io.druid.java.util.metrics.JvmThreadsMonitor</code></td>
<td>Reports Thread statistics in the JVM, like numbers of total, daemon, started, died threads.</td>
</tr>
<tr>
<td><code>io.druid.segment.realtime.RealtimeMetricsMonitor</code></td>
<td>Reports statistics on Realtime nodes.</td>
</tr>
<tr>
<td><code>io.druid.server.metrics.EventReceiverFirehoseMonitor</code></td>
<td>Reports how many events have been queued in the EventReceiverFirehose.</td>
</tr>
<tr>
<td><code>io.druid.server.metrics.QueryCountStatsMonitor</code></td>
<td>Reports how many queries have been successful/failed/interrupted.</td>
</tr>
<tr>
<td><code>io.druid.server.emitter.HttpEmitterMonitor</code></td>
<td>Reports internal metrics of <code>http</code> or <code>parametrized</code> emitter (see below). Must not be used with another emitter type. See the description of the metrics here: https://github.com/druid-io/druid/pull/4973.</td>
</tr>
</tbody></table>

<h3 id="emitting-metrics">Emitting Metrics</h3>

<p>The Druid servers <a href="../operations/metrics.html">emit various metrics</a> and alerts via something we call an Emitter. There are three emitter implementations included with the code, a &quot;noop&quot; emitter, one that just logs to log4j (&quot;logging&quot;, which is used by default if no emitter is specified) and one that does POSTs of JSON events to a server (&quot;http&quot;). The properties for using the logging emitter are described below.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.emitter</code></td>
<td>Setting this value to &quot;noop&quot;, &quot;logging&quot;, &quot;http&quot; or &quot;parametrized&quot; will initialize one of the emitter modules. value &quot;composing&quot; can be used to initialize multiple emitter modules.</td>
<td>noop</td>
</tr>
</tbody></table>

<h4 id="logging-emitter-module">Logging Emitter Module</h4>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.emitter.logging.loggerClass</code></td>
<td>Choices: HttpPostEmitter, LoggingEmitter, NoopServiceEmitter, ServiceEmitter. The class used for logging.</td>
<td>LoggingEmitter</td>
</tr>
<tr>
<td><code>druid.emitter.logging.logLevel</code></td>
<td>Choices: debug, info, warn, error. The log level at which message are logged.</td>
<td>info</td>
</tr>
</tbody></table>

<h4 id="http-emitter-module">Http Emitter Module</h4>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.emitter.http.flushMillis</code></td>
<td>How often the internal message buffer is flushed (data is sent).</td>
<td>60000</td>
</tr>
<tr>
<td><code>druid.emitter.http.flushCount</code></td>
<td>How many messages the internal message buffer can hold before flushing (sending).</td>
<td>500</td>
</tr>
<tr>
<td><code>druid.emitter.http.basicAuthentication</code></td>
<td>Login and password for authentification in &quot;login:password&quot; form, e. g. <code>druid.emitter.http.basicAuthentication=admin:adminpassword</code></td>
<td>not specified = no authentification</td>
</tr>
<tr>
<td>`druid.emitter.http.flushTimeOut</td>
<td>The timeout after which an event should be sent to the endpoint, even if internal buffers are not filled, in milliseconds.</td>
<td>not specified = no timeout</td>
</tr>
<tr>
<td><code>druid.emitter.http.batchingStrategy</code></td>
<td>The strategy of how the batch is formatted. &quot;ARRAY&quot; means <code>[event1,event2]</code>, &quot;NEWLINES&quot; means <code>event1\nevent2</code>, ONLY_EVENTS means <code>event1event2</code>.</td>
<td>ARRAY</td>
</tr>
<tr>
<td><code>druid.emitter.http.maxBatchSize</code></td>
<td>The maximum batch size, in bytes.</td>
<td>the minimum of (10% of JVM heap size divided by 2) or (5191680 (i. e. 5 MB))</td>
</tr>
<tr>
<td><code>druid.emitter.http.batchQueueSizeLimit</code></td>
<td>The maximum number of batches in emitter queue, if there are problems with emitting.</td>
<td>the maximum of (2) or (10% of the JVM heap size divided by 5MB)</td>
</tr>
<tr>
<td><code>druid.emitter.http.minHttpTimeoutMillis</code></td>
<td>If the speed of filling batches imposes timeout smaller than that, not even trying to send batch to endpoint, because it will likely fail, not being able to send the data that fast. Configure this depending based on emitter/successfulSending/minTimeMs metric. Reasonable values are 10ms..100ms.</td>
<td>0</td>
</tr>
<tr>
<td><code>druid.emitter.http.recipientBaseUrl</code></td>
<td>The base URL to emit messages to. Druid will POST JSON to be consumed at the HTTP endpoint specified by this property.</td>
<td>none, required config</td>
</tr>
</tbody></table>

<h4 id="parametrized-http-emitter-module">Parametrized Http Emitter Module</h4>

<p><code>druid.emitter.parametrized.httpEmitting.*</code> configs correspond to the configs of Http Emitter Modules, see above.
Except <code>recipientBaseUrl</code>. E. g. <code>druid.emitter.parametrized.httpEmitting.flushMillis</code>,
<code>druid.emitter.parametrized.httpEmitting.flushCount</code>, etc.</p>

<p>The additional configs are:</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.emitter.parametrized.recipientBaseUrlPattern</code></td>
<td>The URL pattern to send an event to, based on the event&#39;s feed. E. g. <code>http://foo.bar/{feed}</code>, that will send event to <code>http://foo.bar/metrics</code> if the event&#39;s feed is &quot;metrics&quot;.</td>
<td>none, required config</td>
</tr>
</tbody></table>

<h4 id="composing-emitter-module">Composing Emitter Module</h4>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.emitter.composing.emitters</code></td>
<td>List of emitter modules to load e.g. [&quot;logging&quot;,&quot;http&quot;].</td>
<td>[]</td>
</tr>
</tbody></table>

<h4 id="graphite-emitter">Graphite Emitter</h4>

<p>To use graphite as emitter set <code>druid.emitter=graphite</code>. For configuration details please follow this <a href="../development/extensions-contrib/graphite.html">link</a>.</p>

<h3 id="metadata-storage">Metadata Storage</h3>

<p>These properties specify the jdbc connection and other configuration around the metadata storage. The only processes that connect to the metadata storage with these properties are the <a href="../design/coordinator.html">Coordinator</a>, <a href="../design/indexing-service.html">Indexing service</a> and <a href="../design/realtime.html">Realtime Nodes</a>.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.metadata.storage.type</code></td>
<td>The type of metadata storage to use. Choose from &quot;mysql&quot;, &quot;postgresql&quot;, or &quot;derby&quot;.</td>
<td>derby</td>
</tr>
<tr>
<td><code>druid.metadata.storage.connector.connectURI</code></td>
<td>The jdbc uri for the database to connect to</td>
<td>none</td>
</tr>
<tr>
<td><code>druid.metadata.storage.connector.user</code></td>
<td>The username to connect with.</td>
<td>none</td>
</tr>
<tr>
<td><code>druid.metadata.storage.connector.password</code></td>
<td>The <a href="../operations/password-provider.html">Password Provider</a> or String password used to connect with.</td>
<td>none</td>
</tr>
<tr>
<td><code>druid.metadata.storage.connector.createTables</code></td>
<td>If Druid requires a table and it doesn&#39;t exist, create it?</td>
<td>true</td>
</tr>
<tr>
<td><code>druid.metadata.storage.tables.base</code></td>
<td>The base name for tables.</td>
<td>druid</td>
</tr>
<tr>
<td><code>druid.metadata.storage.tables.segments</code></td>
<td>The table to use to look for segments.</td>
<td>druid_segments</td>
</tr>
<tr>
<td><code>druid.metadata.storage.tables.rules</code></td>
<td>The table to use to look for segment load/drop rules.</td>
<td>druid_rules</td>
</tr>
<tr>
<td><code>druid.metadata.storage.tables.config</code></td>
<td>The table to use to look for configs.</td>
<td>druid_config</td>
</tr>
<tr>
<td><code>druid.metadata.storage.tables.tasks</code></td>
<td>Used by the indexing service to store tasks.</td>
<td>druid_tasks</td>
</tr>
<tr>
<td><code>druid.metadata.storage.tables.taskLog</code></td>
<td>Used by the indexing service to store task logs.</td>
<td>druid_taskLog</td>
</tr>
<tr>
<td><code>druid.metadata.storage.tables.taskLock</code></td>
<td>Used by the indexing service to store task locks.</td>
<td>druid_taskLock</td>
</tr>
<tr>
<td><code>druid.metadata.storage.tables.supervisors</code></td>
<td>Used by the indexing service to store supervisor configurations.</td>
<td>druid_supervisors</td>
</tr>
<tr>
<td><code>druid.metadata.storage.tables.audit</code></td>
<td>The table to use for audit history of configuration changes e.g. Coordinator rules.</td>
<td>druid_audit</td>
</tr>
</tbody></table>

<h3 id="deep-storage">Deep Storage</h3>

<p>The configurations concern how to push and pull <a href="../design/segments.html">Segments</a> from deep storage.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.storage.type</code></td>
<td>Choices:local, noop, s3, hdfs, c*. The type of deep storage to use.</td>
<td>local</td>
</tr>
</tbody></table>

<h4 id="local-deep-storage">Local Deep Storage</h4>

<p>Local deep storage uses the local filesystem.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.storage.storageDirectory</code></td>
<td>Directory on disk to use as deep storage.</td>
<td>/tmp/druid/localStorage</td>
</tr>
</tbody></table>

<h4 id="noop-deep-storage">Noop Deep Storage</h4>

<p>This deep storage doesn&#39;t do anything. There are no configs.</p>

<h4 id="s3-deep-storage">S3 Deep Storage</h4>

<p>This deep storage is used to interface with Amazon&#39;s S3.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.s3.accessKey</code></td>
<td>The access key to use to access S3.</td>
<td>none</td>
</tr>
<tr>
<td><code>druid.s3.secretKey</code></td>
<td>The secret key to use to access S3.</td>
<td>none</td>
</tr>
<tr>
<td><code>druid.storage.bucket</code></td>
<td>S3 bucket name.</td>
<td>none</td>
</tr>
<tr>
<td><code>druid.storage.baseKey</code></td>
<td>S3 object key prefix for storage.</td>
<td>none</td>
</tr>
<tr>
<td><code>druid.storage.disableAcl</code></td>
<td>Boolean flag for ACL.</td>
<td>false</td>
</tr>
<tr>
<td><code>druid.storage.archiveBucket</code></td>
<td>S3 bucket name for archiving when running the indexing-service <em>archive task</em>.</td>
<td>none</td>
</tr>
<tr>
<td><code>druid.storage.archiveBaseKey</code></td>
<td>S3 object key prefix for archiving.</td>
<td>none</td>
</tr>
</tbody></table>

<h4 id="hdfs-deep-storage">HDFS Deep Storage</h4>

<p>This deep storage is used to interface with HDFS.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.storage.storageDirectory</code></td>
<td>HDFS directory to use as deep storage.</td>
<td>none</td>
</tr>
</tbody></table>

<h4 id="cassandra-deep-storage">Cassandra Deep Storage</h4>

<p>This deep storage is used to interface with Cassandra.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.storage.host</code></td>
<td>Cassandra host.</td>
<td>none</td>
</tr>
<tr>
<td><code>druid.storage.keyspace</code></td>
<td>Cassandra key space.</td>
<td>none</td>
</tr>
</tbody></table>

<h3 id="caching">Caching</h3>

<p>You can enable caching of results at the broker, historical, or realtime level using following configurations.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Possible Values</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.cache.type</code></td>
<td><code>local</code>, <code>memcached</code></td>
<td>The type of cache to use for queries.</td>
<td><code>local</code></td>
</tr>
<tr>
<td><code>druid.(broker&#124;historical&#124;realtime).cache.unCacheable</code></td>
<td>All druid query types</td>
<td>All query types to not cache.</td>
<td>[&quot;groupBy&quot;, &quot;select&quot;]</td>
</tr>
<tr>
<td><code>druid.(broker&#124;historical&#124;realtime).cache.useCache</code></td>
<td>true, false</td>
<td>Whether to use cache for getting query results.</td>
<td>false</td>
</tr>
<tr>
<td><code>druid.(broker&#124;historical&#124;realtime).cache.populateCache</code></td>
<td>true, false</td>
<td>Whether to populate cache.</td>
<td>false</td>
</tr>
</tbody></table>

<h4 id="local-cache">Local Cache</h4>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.cache.sizeInBytes</code></td>
<td>Maximum cache size in bytes. You must set this if you enabled populateCache/useCache, or else cache size of zero wouldn&#39;t really cache anything.</td>
<td>0</td>
</tr>
<tr>
<td><code>druid.cache.initialSize</code></td>
<td>Initial size of the hashtable backing the cache.</td>
<td>500000</td>
</tr>
<tr>
<td><code>druid.cache.logEvictionCount</code></td>
<td>If non-zero, log cache eviction every <code>logEvictionCount</code> items.</td>
<td>0</td>
</tr>
</tbody></table>

<h4 id="memcache">Memcache</h4>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.cache.expiration</code></td>
<td>Memcached <a href="https://code.google.com/p/memcached/wiki/NewCommands#Standard_Protocol">expiration time</a>.</td>
<td>2592000 (30 days)</td>
</tr>
<tr>
<td><code>druid.cache.timeout</code></td>
<td>Maximum time in milliseconds to wait for a response from Memcached.</td>
<td>500</td>
</tr>
<tr>
<td><code>druid.cache.hosts</code></td>
<td>Comma separated list of Memcached hosts <code>&lt;host:port&gt;</code>.</td>
<td>none</td>
</tr>
<tr>
<td><code>druid.cache.maxObjectSize</code></td>
<td>Maximum object size in bytes for a Memcached object.</td>
<td>52428800 (50 MB)</td>
</tr>
<tr>
<td><code>druid.cache.memcachedPrefix</code></td>
<td>Key prefix for all keys in Memcached.</td>
<td>druid</td>
</tr>
</tbody></table>

<h3 id="indexing-service-discovery">Indexing Service Discovery</h3>

<p>This config is used to find the <a href="../design/indexing-service.html">Indexing Service</a> using Curator service discovery. Only required if you are actually running an indexing service.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.selectors.indexing.serviceName</code></td>
<td>The druid.service name of the indexing service Overlord node. To start the Overlord with a different name, set it with this property.</td>
<td>druid/overlord</td>
</tr>
</tbody></table>

<h3 id="coordinator-discovery">Coordinator Discovery</h3>

<p>This config is used to find the <a href="../design/coordinator.html">Coordinator</a> using Curator service discovery. This config is used by the realtime indexing nodes to get information about the segments loaded in the cluster.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.selectors.coordinator.serviceName</code></td>
<td>The druid.service name of the coordinator node. To start the Coordinator with a different name, set it with this property.</td>
<td>druid/coordinator</td>
</tr>
</tbody></table>

<h3 id="announcing-segments">Announcing Segments</h3>

<p>You can configure how to announce and unannounce Znodes in ZooKeeper (using Curator). For normal operations you do not need to override any of these configs.</p>

<h5 id="batch-data-segment-announcer">Batch Data Segment Announcer</h5>

<p>In current Druid, multiple data segments may be announced under the same Znode.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.announcer.segmentsPerNode</code></td>
<td>Each Znode contains info for up to this many segments.</td>
<td>50</td>
</tr>
<tr>
<td><code>druid.announcer.maxBytesPerNode</code></td>
<td>Max byte size for Znode.</td>
<td>524288</td>
</tr>
<tr>
<td><code>druid.announcer.skipDimensionsAndMetrics</code></td>
<td>Skip Dimensions and Metrics list from segment announcements. NOTE: Enabling this will also remove the dimensions and metrics list from coordinator and broker endpoints.</td>
<td>false</td>
</tr>
<tr>
<td><code>druid.announcer.skipLoadSpec</code></td>
<td>Skip segment LoadSpec from segment announcements. NOTE: Enabling this will also remove the loadspec from coordinator and broker endpoints.</td>
<td>false</td>
</tr>
</tbody></table>

<h3 id="javascript">JavaScript</h3>

<p>Druid supports dynamic runtime extension through JavaScript functions. This functionality can be configured through
the following properties.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.javascript.enabled</code></td>
<td>Set to &quot;true&quot; to enable JavaScript functionality. This affects the JavaScript parser, filter, extractionFn, aggregator, post-aggregator, router strategy, and worker selection strategy.</td>
<td>false</td>
</tr>
</tbody></table>

<div class="note info">
JavaScript-based functionality is disabled by default. Please refer to the Druid <a href="../development/javascript.html">JavaScript programming guide</a> for guidelines about using Druid's JavaScript functionality, including instructions on how to enable it.
</div>

<h3 id="double-column-storage">Double Column storage</h3>

<p>Druid&#39;s storage layer uses a 32-bit float representation to store columns created by the 
doubleSum, doubleMin, and doubleMax aggregators at indexing time. To instead use 64-bit floats
for these columns, please set the system-wide property <code>druid.indexing.doubleStorage=double</code>.
This will become the default behavior in a future version of Druid.</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.indexing.doubleStorage</code></td>
<td>Set to &quot;double&quot; to use 64-bit double representation for double columns.</td>
<td>float</td>
</tr>
</tbody></table>

        </div>
        <div class="col-md-3">
          <div class="searchbox">
            <gcse:searchbox-only></gcse:searchbox-only>
          </div>
          <div id="toc" class="nav toc hidden-print">
          </div>
        </div>
      </div>
    </div>

    <!-- Start page_footer include -->
<footer class="druid-footer">
<div class="container">
  <div class="text-center">
    <p>
    <a href="/technology">Technology</a>&ensp;Â·&ensp;
    <a href="/use-cases">Use Cases</a>&ensp;Â·&ensp;
    <a href="/druid-powered">Powered by Druid</a>&ensp;Â·&ensp;
    <a href="/docs/latest">Docs</a>&ensp;Â·&ensp;
    <a href="https://druid.apache.org/community/">Community</a>&ensp;Â·&ensp;
    <a href="/downloads.html">Download</a>&ensp;Â·&ensp;
    <a href="/faq">FAQ</a>
    </p>
  </div>
  <div class="text-center">
    <a title="Join the user group" href="https://groups.google.com/forum/#!forum/druid-user" target="_blank"><span class="fa fa-comments"></span></a>&ensp;Â·&ensp;
    <a title="Follow Druid" href="https://twitter.com/druidio" target="_blank"><span class="fab fa-twitter"></span></a>&ensp;Â·&ensp;
    <a title="Download via Apache" href="https://www.apache.org/dyn/closer.cgi?path=/incubator/druid/0.14.0-incubating/apache-druid-0.14.0-incubating-bin.tar.gz" target="_blank"><span class="fas fa-feather"></span></a>&ensp;Â·&ensp;
    <a title="GitHub" href="https://github.com/apache/incubator-druid" target="_blank"><span class="fab fa-github"></span></a>
  </div>
  <div class="text-center license">
    Except where otherwise noted, licensed under <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>
  </div>
</div>
</footer>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-40280432-1', 'auto');
  ga('set', 'anonymizeIp', true);
  ga('send', 'pageview');

</script>
<script>
  function trackDownload(type, url) {
    ga('send', 'event', 'download', type, url);
  }
</script>
<script src="//code.jquery.com/jquery.min.js"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
<script src="/assets/js/druid.js"></script>
<!-- stop page_footer include -->


    <script>
    $(function() {
      $(".toc").load("/docs/0.12.1/toc.html");

      // There is no way to tell when .gsc-input will be async loaded into the page so just try to set a placeholder until it works
      var tries = 0;
      var timer = setInterval(function() {
        tries++;
        if (tries > 300) clearInterval(timer);
        var searchInput = $('input.gsc-input');
        if (searchInput.length) {
          searchInput.attr('placeholder', 'Search');
          clearInterval(timer);
        }
      }, 100);
    });
    </script>
  </body>
</html>
